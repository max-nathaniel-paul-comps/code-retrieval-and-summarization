{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open(\"../../data/iyer/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_contents = train_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52997"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for line in train_file_contents:\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 5:\n",
    "        train.append(line.split('\\t')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "from text_data_utils import *\n",
    "from os import path\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = tokenize_texts(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gensim.models.Word2Vec(train_tok).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(text) for text in train_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = tokenized_texts_to_tensor(train_tok, wv, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_fl = np.reshape(train_tensor, (train_tensor.shape[0], train_tensor.shape[1] * train_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52795, 39, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52795, 3900)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor_fl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file_contents = open('../../data/iyer/valid.txt').readlines()\n",
    "val = []\n",
    "for line in val_file_contents:\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 5:\n",
    "        val.append(line.split('\\t')[2])\n",
    "val_tok = tokenize_texts(val)\n",
    "val_tensor = tokenized_texts_to_tensor(val_tok, wv, max_len)\n",
    "val_tensor_fl = np.reshape(val_tensor, (val_tensor.shape[0], val_tensor.shape[1] * val_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_vae import MLPVariationalAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52795 samples, validate on 6599 samples\n",
      "Epoch 1/12\n",
      "52795/52795 [==============================] - 8s 154us/sample - loss: 0.1248 - val_loss: 0.1086\n",
      "Epoch 2/12\n",
      "52795/52795 [==============================] - 7s 127us/sample - loss: 0.1057 - val_loss: 0.1063\n",
      "Epoch 3/12\n",
      "52795/52795 [==============================] - 7s 127us/sample - loss: 0.1018 - val_loss: 0.1019\n",
      "Epoch 4/12\n",
      "52795/52795 [==============================] - 7s 129us/sample - loss: 0.0988 - val_loss: 0.0974\n",
      "Epoch 5/12\n",
      "52795/52795 [==============================] - 7s 125us/sample - loss: 0.0960 - val_loss: 0.0962\n",
      "Epoch 6/12\n",
      "52795/52795 [==============================] - 7s 126us/sample - loss: 0.0938 - val_loss: 0.0926\n",
      "Epoch 7/12\n",
      "52795/52795 [==============================] - 7s 126us/sample - loss: 0.0922 - val_loss: 0.0931\n",
      "Epoch 8/12\n",
      "52795/52795 [==============================] - 7s 127us/sample - loss: 0.0915 - val_loss: 0.0920\n",
      "Epoch 9/12\n",
      "52795/52795 [==============================] - 7s 125us/sample - loss: 0.0901 - val_loss: 0.0913\n",
      "Epoch 10/12\n",
      "52795/52795 [==============================] - 7s 125us/sample - loss: 0.0896 - val_loss: 0.0893\n",
      "Epoch 11/12\n",
      "52795/52795 [==============================] - 7s 125us/sample - loss: 0.0891 - val_loss: 0.0895\n",
      "Epoch 12/12\n",
      "52795/52795 [==============================] - 7s 124us/sample - loss: 0.0885 - val_loss: 0.0904\n"
     ]
    }
   ],
   "source": [
    "model = MLPVariationalAutoEncoder(train_tensor_fl.shape[1], latent_dim, [1024, 512])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit(train_tensor_fl, train_tensor_fl, batch_size=256, epochs=12, verbose=1, shuffle=True,\n",
    "                    validation_data=(val_tensor_fl, val_tensor_fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Training Set) Input:  ['<s>', 'C', '#', '<UNK>', ',', 'setters', 'declaration', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"(Training Set) Input: \", tensor_to_tokenized_texts(np.array([train_tensor[0]]), wv)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = np.reshape(model.predict(np.array([train_tensor_fl[0]])), (1, train_tensor.shape[1], train_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Training Set) Reconstructed:  ['<s>', 'C', '#', 'Datagridview', ',', 'Not', 'inserted', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"(Training Set) Reconstructed: \", tensor_to_tokenized_texts(rec, wv)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Not', 0.6574020385742188),\n",
       " ('direct', 0.6554468870162964),\n",
       " ('Customizing', 0.6533945202827454),\n",
       " ('Frame', 0.6525598764419556),\n",
       " ('Only', 0.6509501934051514),\n",
       " ('xmlns', 0.6459565162658691),\n",
       " ('tracking', 0.6429063081741333),\n",
       " ('trust', 0.6414172649383545),\n",
       " ('Notification', 0.6399063467979431),\n",
       " ('support', 0.639179527759552)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(rec[0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_contents = open('../../data/iyer/test.txt').readlines()\n",
    "test = []\n",
    "for line in test_file_contents:\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 5:\n",
    "        test.append(line.split('\\t')[2])\n",
    "test_tok = tokenize_texts(test)\n",
    "test_tensor = tokenized_texts_to_tensor(test_tok, wv, max_len)\n",
    "test_tensor_fl = np.reshape(test_tensor, (test_tensor.shape[0], test_tensor.shape[1] * test_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11597092485568762"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_tensor_fl, test_tensor_fl, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randrange(test_tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Test Set) Input:  ['<s>', 'Using', 'LINQ', 'to', 'select', 'a', 'random', 'XML', 'node', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"(Test Set) Input: \", tensor_to_tokenized_texts(np.array([test_tensor[random_idx]]), wv)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Test Set) Reconstructed:  ['<s>', 'Join', 'Group', 'to', 'remove', 'a', 'contents', 'excel', 'contents', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"(Test Set) Reconstructed: \", tensor_to_tokenized_texts(np.reshape(model.predict(np.array([test_tensor_fl[random_idx]])), (1, test_tensor.shape[1], test_tensor.shape[2])), wv)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
