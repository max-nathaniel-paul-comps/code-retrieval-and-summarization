{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open(\"../../data/iyer/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_contents = train_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52997"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for line in train_file_contents:\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 5:\n",
    "        train.append(line.split('\\t')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "from text_data_utils import *\n",
    "from os import path\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = tokenize_texts(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gensim.models.Word2Vec(train_tok).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(text) for text in train_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = tokenized_texts_to_tensor(train_tok, wv, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.73879492,  0.55274993, -0.35729647, -0.52002335,  0.12782197,\n",
       "        0.11938381,  0.82348132, -0.48800877,  0.32269821,  1.74547958,\n",
       "        0.73873854,  0.140288  , -0.392452  ,  0.30661142, -0.55629641,\n",
       "       -0.16242556,  0.47705811, -1.7649827 , -1.06810749,  0.08043519,\n",
       "       -0.70535427, -0.01237084,  0.68049383,  0.18081552,  0.86641955,\n",
       "        0.84606814,  0.01800916, -0.29523399, -0.00870313, -1.0394522 ,\n",
       "        0.2131716 ,  0.96355474,  0.01078537,  0.90590084,  1.18876171,\n",
       "        0.46406162,  0.42419285, -0.53306198,  0.73095047,  0.67578936,\n",
       "       -0.67718387, -0.19723158,  0.59144628, -0.40570411,  1.3554765 ,\n",
       "        0.90622997, -0.66121393,  0.62829822,  0.83926123,  0.17268981,\n",
       "        0.74130988,  0.64965093,  0.17344132, -0.24491772, -0.76218379,\n",
       "        0.29207313, -0.70666963,  0.19077501,  0.70406359,  0.28889212,\n",
       "       -0.45597586, -0.40071785,  0.1031318 ,  0.20170197, -0.08252058,\n",
       "       -0.57074344, -0.10505958,  0.96575826,  0.81126976,  0.53661132,\n",
       "       -0.84392053,  0.01215485,  0.16129655,  1.56242883,  0.72552007,\n",
       "       -0.08046392,  0.41417512, -0.4621802 , -0.23334901, -0.1759802 ,\n",
       "        1.7634933 ,  0.67353064,  0.00236652, -0.32732236,  0.531138  ,\n",
       "       -0.80331635,  0.87759209,  0.43211713, -0.83225375,  0.20671491,\n",
       "       -0.76682746, -0.37411585,  0.54733884,  0.20834744,  0.39713278,\n",
       "       -0.20140876,  0.09864437, -1.00909722, -1.11410916, -0.47480005])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_fl = np.reshape(train_tensor, (train_tensor.shape[0], train_tensor.shape[1] * train_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52795, 39, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52795, 3900)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor_fl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_file_contents = open('../../data/iyer/valid.txt').readlines()\n",
    "val = []\n",
    "for line in val_file_contents:\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 5:\n",
    "        val.append(line.split('\\t')[2])\n",
    "val_tok = tokenize_texts(val)\n",
    "val_tensor = tokenized_texts_to_tensor(val_tok, wv, max_len)\n",
    "val_tensor_fl = np.reshape(val_tensor, (val_tensor.shape[0], val_tensor.shape[1] * val_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_vae import MLPVariationalAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52795 samples, validate on 6599 samples\n",
      "Epoch 1/20\n",
      "52795/52795 [==============================] - 8s 160us/sample - loss: 0.0789 - val_loss: 0.0611\n",
      "Epoch 2/20\n",
      "52795/52795 [==============================] - 6s 123us/sample - loss: 0.0514 - val_loss: 0.0490\n",
      "Epoch 3/20\n",
      "52795/52795 [==============================] - 6s 122us/sample - loss: 0.0440 - val_loss: 0.0418\n",
      "Epoch 4/20\n",
      "52795/52795 [==============================] - 6s 122us/sample - loss: 0.0388 - val_loss: 0.0388\n",
      "Epoch 5/20\n",
      "52795/52795 [==============================] - 6s 123us/sample - loss: 0.0359 - val_loss: 0.0355\n",
      "Epoch 6/20\n",
      "52795/52795 [==============================] - 6s 123us/sample - loss: 0.0336 - val_loss: 0.0337\n",
      "Epoch 7/20\n",
      "52795/52795 [==============================] - 6s 123us/sample - loss: 0.0316 - val_loss: 0.0321\n",
      "Epoch 8/20\n",
      "52795/52795 [==============================] - 7s 123us/sample - loss: 0.0302 - val_loss: 0.0314\n",
      "Epoch 9/20\n",
      "52795/52795 [==============================] - 7s 126us/sample - loss: 0.0291 - val_loss: 0.0321\n",
      "Epoch 10/20\n",
      "52795/52795 [==============================] - 7s 136us/sample - loss: 0.0279 - val_loss: 0.0295\n",
      "Epoch 11/20\n",
      "52795/52795 [==============================] - 7s 126us/sample - loss: 0.0268 - val_loss: 0.0280\n",
      "Epoch 12/20\n",
      "52795/52795 [==============================] - 7s 124us/sample - loss: 0.0255 - val_loss: 0.0269\n",
      "Epoch 13/20\n",
      "52795/52795 [==============================] - 7s 125us/sample - loss: 0.0251 - val_loss: 0.0261\n",
      "Epoch 14/20\n",
      "52795/52795 [==============================] - 7s 126us/sample - loss: 0.0243 - val_loss: 0.0251\n",
      "Epoch 15/20\n",
      "52795/52795 [==============================] - 7s 127us/sample - loss: 0.0238 - val_loss: 0.0286\n",
      "Epoch 16/20\n",
      "52795/52795 [==============================] - 7s 127us/sample - loss: 0.0233 - val_loss: 0.0252\n",
      "Epoch 17/20\n",
      "52795/52795 [==============================] - 7s 125us/sample - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 18/20\n",
      "52795/52795 [==============================] - 7s 124us/sample - loss: 0.0222 - val_loss: 0.0236\n",
      "Epoch 19/20\n",
      "52795/52795 [==============================] - 7s 126us/sample - loss: 0.0215 - val_loss: 0.0240\n",
      "Epoch 20/20\n",
      "52795/52795 [==============================] - 7s 126us/sample - loss: 0.0212 - val_loss: 0.0233\n"
     ]
    }
   ],
   "source": [
    "model = MLPVariationalAutoEncoder(train_tensor_fl.shape[1], latent_dim, [1024, 512], final_activation='linear')\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model.fit(train_tensor_fl, train_tensor_fl, batch_size=256, epochs=20, verbose=1, shuffle=True,\n",
    "                    validation_data=(val_tensor_fl, val_tensor_fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed()\n",
    "random_idx = random.randrange(train_tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Training Set) Input:  ['<s>', 'How', 'can', 'I', 'display', 'multiple', 'images', 'in', 'a', 'loop', 'in', 'a', 'WP7', 'app', '?', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"(Training Set) Input: \", tensor_to_tokenized_texts(np.array([train_tensor[random_idx]]), wv)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = np.reshape(model.predict(np.array([train_tensor_fl[random_idx]])), (1, train_tensor.shape[1], train_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Training Set) Reconstructed:  ['<s>', 'How', 'can', 'I', 'display', 'multiple', 'pdf', 'in', 'a', 'loop', 'in', 'a', 'timer', 'app', '?', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"(Training Set) Reconstructed: \", tensor_to_tokenized_texts(rec, wv)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('display', 0.9453029632568359),\n",
       " ('add', 0.8929032683372498),\n",
       " ('show', 0.8895425796508789),\n",
       " ('change', 0.8889898657798767),\n",
       " ('retrieve', 0.8829615116119385),\n",
       " ('delete', 0.8801358342170715),\n",
       " ('print', 0.8584847450256348),\n",
       " ('move', 0.851596474647522),\n",
       " ('bind', 0.8342567682266235),\n",
       " ('hide', 0.8299027681350708)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(rec[0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_contents = open('../../data/iyer/test.txt').readlines()\n",
    "test = []\n",
    "for line in test_file_contents:\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 5:\n",
    "        test.append(line.split('\\t')[2])\n",
    "test_tok = tokenize_texts(test)\n",
    "test_tensor = tokenized_texts_to_tensor(test_tok, wv, max_len)\n",
    "test_tensor_fl = np.reshape(test_tensor, (test_tensor.shape[0], test_tensor.shape[1] * test_tensor.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047301981562573835"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_tensor_fl, test_tensor_fl, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed()\n",
    "random_idx = random.randrange(test_tensor.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Test Set) Input:  ['<s>', 'How', 'to', 'call', 'a', 'JavaScript', 'function', 'multiple', 'times', 'in', 'a', 'loop', 'on', 'page', 'reload', 'with', 'ASP', '.', 'NET', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"(Test Set) Input: \", tensor_to_tokenized_texts(np.array([test_tensor[random_idx]]), wv)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Test Set) Reconstructed:  ['<s>', 'How', 'to', 'call', 'a', 'Direct', 'function', 'multiple', 'Criteria', 'in', 'a', 'dictionary', 'on', 'repeater', 'SqlDataSource', 'in', '.', 'Asp', 'net', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(\"(Test Set) Reconstructed: \", tensor_to_tokenized_texts(np.reshape(model.predict(np.array([test_tensor_fl[random_idx]])), (1, test_tensor.shape[1], test_tensor.shape[2])), wv)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
